{"cells":[{"cell_type":"code","execution_count":55,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-18T08:02:12.998385Z","iopub.status.busy":"2024-03-18T08:02:12.997701Z","iopub.status.idle":"2024-03-18T08:02:13.003401Z","shell.execute_reply":"2024-03-18T08:02:13.002298Z","shell.execute_reply.started":"2024-03-18T08:02:12.998352Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","#import numpy as np # linear algebra\n","#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","#import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","    #for filename in filenames:\n","        #print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T08:03:38.093117Z","iopub.status.busy":"2024-03-24T08:03:38.092794Z","iopub.status.idle":"2024-03-24T09:13:12.564051Z","shell.execute_reply":"2024-03-24T09:13:12.563265Z","shell.execute_reply.started":"2024-03-24T08:03:38.093090Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["檔案 'saved_model.h5' 不存在，無需刪除。\n","模型訓練完成\n","驗證集中的圖片數量: 29219\n","1.\n","\n","(1)The confusion matrix:\n","[[3150    7   12    2    3   10   36    0    7    7]\n"," [   2 3180    6    6   19    6    3    4    0    4]\n"," [  22   37 2580  125    5   12    3   28   12    6]\n"," [   1    0   11 2892    0   14    0    6    7    7]\n"," [   1   14    2    3 2686    5    7    2    2   48]\n"," [   1    2    1   61    2 2592   12    2    5    4]\n"," [  20   17    0    0   12   19 2750    0    4    0]\n"," [   3   20   11   42   18    1    0 2869    1   82]\n"," [  46   12   12   59   21   76   46    2 2454   61]\n"," [  18    5    1   37   61   19    2   19    9 2706]]\n","\n","(2)Top-1 Accuracy: 0.9534549437010165\n","Top-1 分子: 27859\n","Top-1 分母: 29219\n","\n","(3)Top-3 Accuracy: 0.9946952325541599\n","Top-3 分子: 29064\n","Top-3 分母: 29219\n"]}],"source":["# 接下來的代碼\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input,Dropout\n","from tensorflow.keras.models import Sequential, load_model\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from keras.utils import to_categorical\n","from tensorflow.keras.models import load_model\n","\n","# 忽略警告\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","\n","# 屏蔽特定類型的警告\n","\n","# 初始化圖像和標籤列表\n","images = []\n","labels = []\n","\n","# 初始化驗證集的資料\n","val_images_accumulated = []\n","val_labels_accumulated = []\n","\n","# 刪除檔案\n","# 設置模型保存路徑\n","model_path = 'saved_model.h5'\n","if os.path.exists(model_path):\n","    os.remove(model_path)\n","    print(f\"檔案 '{model_path}' 已成功刪除。\")\n","else:\n","    print(f\"檔案 '{model_path}' 不存在，無需刪除。\")\n","\n","# 檢查是否已經存在保存的模型，如果是則加載它\n","if os.path.exists(model_path):\n","    model = load_model(model_path)\n","else:\n","    # 如果模型不存在，則創建一個新的模型\n","\n","    model = Sequential([\n","      Input(shape=(64, 64,1)),\n","      # Reshape to add a single channel dimension\n","      Conv2D(128, (3, 3), activation='relu'),\n","      MaxPooling2D((2, 2)),\n","      Conv2D(128, (3, 3), activation='relu'),\n","      MaxPooling2D((2, 2)),\n","      Conv2D(128, (3, 3), activation='relu'),\n","      Flatten(),\n","      Dense(256, activation='relu'),\n","      Dense(10, activation='softmax')\n","    ])\n","\n","\n","# 讀取標籤資料\n","for filename in os.listdir('/kaggle/input/advancedml-hw2/hw2/HW2_MNIST_train'):\n","\n","    if filename.endswith('.txt'):\n","        labels_file_path = os.path.join('/kaggle/input/advancedml-hw2/hw2/HW2_MNIST_train', filename)\n","        with open(labels_file_path, 'r') as file:\n","            lines = file.readlines()\n","\n","        # 處理每張圖像\n","        for line in lines:\n","            parts = line.strip().split('\\t')\n","            digit = int(parts[0])\n","            image_path = os.path.join('/kaggle/input/advancedml-hw2/hw2/HW2_MNIST_train', filename.replace('.txt', '.png'))\n","            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","            img = cv2.resize(img, (64, 64))\n","            if img is None:\n","                print(f\"Error reading image: {image_path}\")\n","                continue\n","            digit_img = img.astype(np.float32) / 255.0\n","            images.append(digit_img)\n","            labels.append(digit)\n","            #print('label=',labels)\n","            # 如果已經收集到1000張圖片，則執行訓練\n","            if len(images) == 1000:\n","                # 將列表轉換為NumPy數組\n","                images_np = np.array(images)\n","                labels_np = np.array(labels)\n","\n","                # 將標籤進行獨熱編碼\n","                labels_one_hot = to_categorical(labels_np, num_classes=10)\n","\n","                # 加載模型\n","                if os.path.exists(model_path):\n","                    model = load_model(model_path)\n","\n","                # 將數據集劃分為訓練集和驗證集7:3\n","                train_images, val_images, train_labels, val_labels = train_test_split(images_np, labels_one_hot, test_size=0.3, random_state=42)\n","\n","                # 累積驗證集的資料\n","                val_images_accumulated.extend(val_images)\n","                val_labels_accumulated.extend(val_labels)\n","                num_val_images = len(val_images_accumulated)\n","\n","\n","                # 編譯模型\n","                model.compile(optimizer='adam',\n","                              loss='categorical_crossentropy',\n","                              metrics=['accuracy'])\n","\n","                # 訓練模型\n","                model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_data=(np.array(val_images_accumulated), np.array(val_labels_accumulated)), verbose=0)\n","\n","                # 保存訓練好的模型\n","                model.save(model_path)\n","\n","                # 清空資料\n","                images = []\n","                labels = []\n","\n","                \n","\n","# 確保最後一批資料也被訓練到\n","if len(images) > 0:\n","    images_np = np.array(images)\n","    labels_np = np.array(labels)\n","    labels_one_hot = to_categorical(labels_np, num_classes=10)\n","    train_images, val_images, train_labels, val_labels = train_test_split(images_np, labels_one_hot, test_size=0.3, random_state=42)\n","\n","    # 累積驗證集的資料\n","    val_images_accumulated.extend(val_images)\n","    val_labels_accumulated.extend(val_labels)\n","\n","    model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_data=(np.array(val_images_accumulated), np.array(val_labels_accumulated)), verbose=0)\n","\n","print('模型訓練完成')\n","\n","num_val_images = len(val_images_accumulated)\n","print(\"驗證集中的圖片數量:\", num_val_images)\n","\n","# 將 val_images_accumulated 中的圖像形狀從 (900, 64, 64) 轉換為 (900, 64, 64, 1)\n","val_images_accumulated1 = np.expand_dims(val_images_accumulated, axis=-1)\n","\n","# 使用模型預測\n","val_pred = model.predict(val_images_accumulated1, verbose=0)\n","val_pred_labels = np.argmax(val_pred, axis=1)\n","val_true_labels = np.argmax(val_labels_accumulated, axis=1)\n","val_conf_matrix = confusion_matrix(val_true_labels, val_pred_labels)\n","\n","# 驗證集Top-1\n","val_top1_acc = accuracy_score(val_true_labels, val_pred_labels)\n","val_top1_num = np.sum(val_true_labels == val_pred_labels)\n","val_top1_denom = len(val_true_labels)\n","\n","# 驗證集Top-3\n","val_top3_acc = np.mean([1 if true_label in pred_labels.argsort()[-3:] else 0 for true_label, pred_labels in zip(val_true_labels, val_pred)])\n","val_top3_num = np.sum([1 if true_label in pred_labels.argsort()[-3:] else 0 for true_label, pred_labels in zip(val_true_labels, val_pred)])\n","val_top3_denom = len(val_true_labels)\n","\n","# 打印驗證集指標\n","print(\"1.\")\n","print(\"\\n(1)The confusion matrix:\")\n","print(val_conf_matrix)\n","print(\"\\n(2)Top-1 Accuracy:\", val_top1_acc)\n","print(\"Top-1 分子:\", val_top1_num)\n","print(\"Top-1 分母:\", val_top1\n","      _denom)\n","print(\"\\n(3)Top-3 Accuracy:\", val_top3_acc)\n","print(\"Top-3 分子:\", val_top3_num)\n","print(\"Top-3 分母:\", val_top3_denom)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-19T14:26:22.141255Z","iopub.status.busy":"2024-03-19T14:26:22.140499Z","iopub.status.idle":"2024-03-19T14:55:52.699788Z","shell.execute_reply":"2024-03-19T14:55:52.699014Z","shell.execute_reply.started":"2024-03-19T14:26:22.141225Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["檔案 'test_results.csv' 不存在，無需刪除。\n","完成預測檔 HW2_prob1.csv\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.models import load_model\n","\n","# 刪除檔案\n","model_path = 'test_results.csv'\n","if os.path.exists(model_path):\n","    os.remove(model_path)\n","    print(f\"檔案 '{model_path}' 已成功刪除。\")\n","else:\n","    print(f\"檔案 '{model_path}' 不存在，無需刪除。\")\n","    \n","model = load_model('/kaggle/working/saved_model.h5')\n","\n","# Path to the folder containing test images\n","test_folder_path = '/kaggle/input/advancedml-hw2/hw2/HW2_MNIST_test'\n","\n","# Initialize lists to store image paths and their corresponding predictions\n","test_image_paths = []\n","predictions = []\n","\n","# Loop through each file in the test folder\n","for filename in os.listdir(test_folder_path):\n","    # Check if the file is an image\n","    if filename.endswith('.png'):\n","        # Read the image\n","        image_path = os.path.join(test_folder_path, filename)\n","        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","        img = cv2.resize(img, (64, 64))\n","        if img is None:\n","            print(f\"Error reading image: {image_path}\")\n","            continue\n","        digit_img = img.astype(np.float32) / 255.0\n","\n","        # Predict the label using the trained model\n","        pred = model.predict(np.expand_dims(digit_img, axis=0), verbose=0)  # Use np.expand_dims to add batch dimension\n","        predicted_label = np.argmax(pred)\n","\n","        # Store the image path and predicted label\n","        test_image_paths.append(filename)\n","        predictions.append(predicted_label)\n","\n","# Create a DataFrame to store the results\n","results_df = pd.DataFrame({'image': test_image_paths, 'class': predictions})\n","\n","# Write the DataFrame to a CSV file\n","results_df.to_csv('HW2_prob1.csv', index=False)\n","print('完成預測檔 HW2_prob1.csv')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4589908,"isSourceIdPinned":false,"sourceId":7831668,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
